<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Leif Hancox-Li</title>
    <link>https://boltzmann-brain.github.io/</link>
    <description>Recent content on Leif Hancox-Li</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 05 Feb 2021 16:23:44 -0400</lastBuildDate>
    
	<atom:link href="https://boltzmann-brain.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Epistemic dynamics and gender in the philosophy of physics</title>
      <link>https://boltzmann-brain.github.io/posts/dotson-phil-physics/</link>
      <pubDate>Fri, 05 Feb 2021 16:23:44 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/dotson-phil-physics/</guid>
      <description>There was no shortage of women who entered my PhD program wanting to do philosophy of physics. There were as many of them, in my time there, as there were men interested in the same. Yet in the end, much fewer women ended up specializing in that, by the time they left the program.
Why? Here&amp;rsquo;s what would happen:
 A woman would be admitted with a philosophy of physics interest and enthusiastically start taking the philosophy of physics courses.</description>
    </item>
    
    <item>
      <title>Why I Don&#39;t Defend Professional Philosophy</title>
      <link>https://boltzmann-brain.github.io/posts/ethics/</link>
      <pubDate>Sun, 19 Jul 2020 15:38:39 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/ethics/</guid>
      <description>As a former professional philosopher who now does research on responsible AI, I&amp;rsquo;ve been to multiple events where someone working on the social impacts of AI will make a negative remark about philosophy. Typically, their criticism implicitly targets the dominant strain of academic philosophy in the Anglophone tradition, encompassing the various analytic approaches to ethics. As an ex-philosopher who finds my background in philosophy of science sometimes useful to my AI research, I might be expected to defend my former field, but in fact I largely agree with the criticisms and think on the whole that it would not be helpful to respond to these criticisms by listing the various &amp;ldquo;exceptions&amp;rdquo; to the rule.</description>
    </item>
    
    <item>
      <title>Literary Social Science in Milkman and Uncanny Valley</title>
      <link>https://boltzmann-brain.github.io/posts/milkman-uncanny-valley/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/milkman-uncanny-valley/</guid>
      <description>I recently happened to read two books in close succession that, unbeknownst to me before my readings, were both what I&amp;rsquo;m calling literary social science&amp;mdash;which is particularly striking given that one book is fiction and the other is a memoir. Anna Burns&amp;rsquo; Milkman is a fictional narrative by a teenager in Northern Ireland during the Troubles, and Anna Wiener&amp;rsquo;s Uncanny Valley is a memoir of Wiener&amp;rsquo;s stint working in Silicon Valley.</description>
    </item>
    
    <item>
      <title>Papers</title>
      <link>https://boltzmann-brain.github.io/papers/</link>
      <pubDate>Sun, 07 Jul 2019 21:48:16 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/papers/</guid>
      <description>A list of my published papers and preprints in philosophy of machine learning, feminist philosophy, and philosophy of physics. You can also view a copy of my academic CV here.
Philosophy of Machine Learning &amp;ldquo;Epistemic values in feature importance methods: Lessons from feminist epistemology&amp;rdquo;. Forthcoming at the Conference on Fairness, Accountability, and Transparency (FAccT â€™21).
 Argues that many popular feature importance methods in ML adhere to a methodology and view of objectivity that is in tension with feminist epistemology.</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>https://boltzmann-brain.github.io/resume/</link>
      <pubDate>Sat, 06 Jul 2019 16:42:37 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/resume/</guid>
      <description>My resume is also available in PDF form. Alternatively, you can view my LinkedIn profile.
Work Senior Data Scientist, Capital One 2020 - present
 Do research on fair and explainable machine learning, including internal user studies and peer-reviewed work on methodological issues. Educate other Capital One data scientists on best practices for responsible AI, in both text and talk formats.  Senior Technical Writer, Capital One 2019 - 2020</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://boltzmann-brain.github.io/about/</link>
      <pubDate>Mon, 27 May 2019 21:56:58 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/about/</guid>
      <description>I&amp;rsquo;m an NYC-based data scientist who does research and education on responsible AI. Prior to this, I wrote developer-oriented and user-facing documentation. An even longer time ago, I got a PhD in philosophy after stints in computer vision and physics. You can contact me at [my first name]@fastmail.com.</description>
    </item>
    
  </channel>
</rss>