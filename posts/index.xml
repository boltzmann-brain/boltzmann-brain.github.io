<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Leif Hancox-Li</title>
    <link>https://boltzmann-brain.github.io/posts/</link>
    <description>Recent content in Posts on Leif Hancox-Li</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 30 Apr 2023 13:04:09 -0500</lastBuildDate><atom:link href="https://boltzmann-brain.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>This week in Responsible AI: Apr 30, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-9/</link>
      <pubDate>Sun, 30 Apr 2023 13:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-9/</guid>
      <description>Law/Policy   The EU and U.S. diverge on AI regulation
  Copyright Showdown: AI&amp;rsquo;s Next Frontier
  FTC Chair Khan and Officials from DOJ, CFPB and EEOC Release Joint Statement on AI
  Europe spins up AI research hub to apply accountability rules on Big Tech
  AI Harms   A Wisconsin school dropout risk algorithm &amp;ldquo;generated false alarms about Black and Hispanic students not graduating on time at a significantly greater rate than it did for their White classmates&amp;rdquo;</description>
    </item>
    
    <item>
      <title>This week in Responsible AI: Apr 21, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-8/</link>
      <pubDate>Thu, 20 Apr 2023 13:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-8/</guid>
      <description>General   NeurIPS announces a code of ethics
  The Myth of Objective Data
  How do you design an AI ethics board that actually works?
  Law/Policy   How We Think About Copyright and AI Art
  Italy gives OpenAI initial to-do list for lifting ChatGPT suspension order
  OpenAI could soon be banned from the entire EU for violating GDPR
  Drake deepfake raises copyright issues: 1, 2</description>
    </item>
    
    <item>
      <title>This week in Responsible AI: Apr 12, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-7/</link>
      <pubDate>Wed, 12 Apr 2023 13:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-7/</guid>
      <description>General  AI Now released their annual report. Read about LLMs, antitrust, accountability, workplace surveillance, industrial policy, and more!  Law/Policy   ChatGPT and Copyright: The Ultimate Appropriation
  Foundation Models and Fair Use
  Vanderbilt Law Review: Humans in the Loop
  Defining Disparate Treatment: A Research Agenda For Our Times
  Transparency   Contextual transparency for automated decision systems (PDF)
  The Algorithmic Transparency Playbook</description>
    </item>
    
    <item>
      <title>The past two weeks in Responsible AI: Apr 3, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-6/</link>
      <pubDate>Mon, 03 Apr 2023 13:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-6/</guid>
      <description>Law/Policy   How California and other states are tackling AI legislation
  AI might have already set the stage for the next tech monopoly
  FTC blog post on &amp;ldquo;AI deception for sale&amp;rdquo;
  ChatGPT banned in Italy over privacy concerns
  Governing generative foundation models
  Venture capitalists think that the EU AI Act will make European startups in AI less competitive.
  In Gonzalez v.</description>
    </item>
    
    <item>
      <title>This Week (10 days) in Responsible AI: March 20, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-5/</link>
      <pubDate>Sun, 19 Mar 2023 23:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-5/</guid>
      <description>I was a little busy last week so this update is a few days delayed!
Law/Policy   DoNotPay sued for &amp;ldquo;robot lawyer&amp;rdquo; claims
  The UK and EU establish positions as regulatory first movers while the US watches
  Generative AI Doesn&amp;rsquo;t (and Shouldn&amp;rsquo;t) Have a Liability Shield
  Auditing AI tools used in employment decisions
  The dangers of AI-generated microlegislation
  The shake-up of the tech sector shows: we must learn from finance regulation</description>
    </item>
    
    <item>
      <title>This Week in Responsible AI: March 9, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-4/</link>
      <pubDate>Wed, 08 Mar 2023 23:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-4/</guid>
      <description>Law/Policy   BetterHelp settles with FTC for leaking personal health information to social media platforms
  Ten Legal and Business Risks of Chatbots and Generative AI
  What the EU&amp;rsquo;s Digital Services Act and Digital Markets Act will do
  Responsible AI: What Does It Take to Turn Principles into Practice?
  Is it time to hit the pause button on AI?
  Suresh Venkatasubramanian&amp;rsquo;s remarks at a Senate committee hearing on AI: Risks and Opportunities</description>
    </item>
    
    <item>
      <title>This Week in Responsible AI: March 2, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-3/</link>
      <pubDate>Tue, 28 Feb 2023 23:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-3/</guid>
      <description>Law/Policy   The FTC comments on AI hype.
  The FTC and CFPB seek public comment on &amp;ldquo;how algorithms, automated decision-making, artificial intelligence, or similar technology are used in the tenant screening process&amp;rdquo;.
  What&amp;rsquo;s in a name? Getting the definition of Artificial Intelligence right in the EU&amp;rsquo;s AI Act
  NYC is about to regulate AI in hiring. Critics say the new law doesn&amp;rsquo;t do much</description>
    </item>
    
    <item>
      <title>This Week in Responsible AI: February 23, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-2/</link>
      <pubDate>Wed, 22 Feb 2023 23:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-2/</guid>
      <description>ML harms   &amp;ldquo;the online courses further support Google and IBM to consolidate and even expand their position of power by recruiting new AI talent and by securing their infrastructures and models to become the dominant ones&amp;hellip; the companies not only influence greatly how ML is represented, but also how these representations in turn influence and direct current ML research and development, as well as the societal effects of their products&amp;rdquo;</description>
    </item>
    
    <item>
      <title>This Week in Responsible AI: February 16, 2023</title>
      <link>https://boltzmann-brain.github.io/posts/twrai-1/</link>
      <pubDate>Wed, 15 Feb 2023 23:04:09 -0500</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/twrai-1/</guid>
      <description>Designing AI
  Speculative friction
  What went wrong with design thinking
  Climate
 AI&amp;rsquo;s carbon footprint  Diversity
 More than 30% of girls in tech donâ€™t become tech undergrads  Legal/policy
 The US patent office issued an RFC on intellectual property made with AI  Explainability
 Facebook releases a &amp;ldquo;Why am I seeing this ad?&amp;rdquo; tool  Fairness
 Common methods to remove ML bias fail to correct for &amp;ldquo;social norm bias&amp;rdquo;  Privacy</description>
    </item>
    
    <item>
      <title>Der Spiegel&#39;s 1987 interview with Joseph Weizenbaum</title>
      <link>https://boltzmann-brain.github.io/posts/weizenbaum/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/weizenbaum/</guid>
      <description>A few years ago, I found this 1987 interview with the early AI researcher-turned-AI skeptic Joseph Weizenbaum. It covers a lot of ground, such as the military-industrial complex, whether computers can capture human experience, and other points that today&amp;rsquo;s AI skeptics will be sympathetic to. (These themes were also covered in longer form in his book, Computer Power and Human Reason.) As far as I know, there isn&amp;rsquo;t an English translation of this interview available.</description>
    </item>
    
    <item>
      <title>My journey from academia into technical writing</title>
      <link>https://boltzmann-brain.github.io/posts/academia-tech-writing/</link>
      <pubDate>Fri, 26 Mar 2021 18:47:10 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/academia-tech-writing/</guid>
      <description>Occasionally, unhappy academics ask me for advice on how to get non-academic jobs. Few of them consider technical writing as a career option, and I think more of them should&amp;mdash;technical writing values skills that many academics already have, and provides similar intellectual challenges, but with greater career flexibility than academia has.
Here, I&amp;rsquo;ll describe my journey into technical writing and why I found it fulfilling, adding on some basic advice and views on the technical writing job market.</description>
    </item>
    
    <item>
      <title>Alternative computing styles and gender</title>
      <link>https://boltzmann-brain.github.io/posts/pluralism-cs/</link>
      <pubDate>Mon, 15 Mar 2021 19:40:21 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/pluralism-cs/</guid>
      <description>Lizzie Kumar and I recently co-authored a paper at FAccT that applied feminist epistemology to explanation methods in machine learning. People must have liked it, because we won a best paper award for it. One of the points we made, borrowing from feminist epistemology, is that we could do with more epistemological pluralism when it comes to evaluating these methods, and that we should consider if certain dominant computing values cause us to over-trust some explanation methods.</description>
    </item>
    
    <item>
      <title>Epistemic dynamics and gender in the philosophy of physics</title>
      <link>https://boltzmann-brain.github.io/posts/dotson-phil-physics/</link>
      <pubDate>Fri, 05 Feb 2021 16:23:44 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/dotson-phil-physics/</guid>
      <description>There was no shortage of women who entered my PhD program wanting to do philosophy of physics. There were as many of them, in my time there, as there were men interested in the same. Yet in the end, much fewer women ended up specializing in that, by the time they left the program.
Why? Here&amp;rsquo;s what would happen:
  A woman would be admitted with a philosophy of physics interest and enthusiastically start taking the philosophy of physics courses.</description>
    </item>
    
    <item>
      <title>Why I Don&#39;t Defend Professional Philosophy</title>
      <link>https://boltzmann-brain.github.io/posts/ethics/</link>
      <pubDate>Sun, 19 Jul 2020 15:38:39 -0400</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/ethics/</guid>
      <description>As a former professional philosopher who now does research on responsible AI, I&amp;rsquo;ve been to multiple events where someone working on the social impacts of AI will make a negative remark about philosophy. Typically, their criticism implicitly targets the dominant strain of academic philosophy in the Anglophone tradition, encompassing the various analytic approaches to ethics. As an ex-philosopher who finds my background in philosophy of science sometimes useful to my AI research, I might be expected to defend my former field, but in fact I largely agree with the criticisms and think on the whole that it would not be helpful to respond to these criticisms by listing the various &amp;ldquo;exceptions&amp;rdquo; to the rule.</description>
    </item>
    
    <item>
      <title>Literary Social Science in Milkman and Uncanny Valley</title>
      <link>https://boltzmann-brain.github.io/posts/milkman-uncanny-valley/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://boltzmann-brain.github.io/posts/milkman-uncanny-valley/</guid>
      <description>I recently happened to read two books in close succession that, unbeknownst to me before my readings, were both what I&amp;rsquo;m calling literary social science&amp;mdash;which is particularly striking given that one book is fiction and the other is a memoir. Anna Burns&#39; Milkman is a fictional narrative by a teenager in Northern Ireland during the Troubles, and Anna Wiener&amp;rsquo;s Uncanny Valley is a memoir of Wiener&amp;rsquo;s stint working in Silicon Valley.</description>
    </item>
    
  </channel>
</rss>
